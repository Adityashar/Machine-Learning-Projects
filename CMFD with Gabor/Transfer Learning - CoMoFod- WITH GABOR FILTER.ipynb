{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_array():\n",
    "    images = []\n",
    "    target = []\n",
    "\n",
    "    directory = \"E:/CoMoFoD_small_v2\"\n",
    "    image_list = os.listdir(directory)\n",
    "\n",
    "    for name in image_list:\n",
    "        \n",
    "        location = os.path.join(directory, name)\n",
    "        image = cv2.imread(location)\n",
    "        \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "        \n",
    "        if 'F' in name:\n",
    "            images.append(image)\n",
    "            target.append(1)\n",
    "        elif 'O' in name:\n",
    "            images.append(image)\n",
    "            target.append(0)\n",
    "                \n",
    "    return images, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, target = create_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D, BatchNormalization, AveragePooling2D\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import pickle\n",
    "from keras.initializers import glorot_normal\n",
    "from keras.initializers import Constant\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_target = shuffle(images, target, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure()\n",
    "g = cv2.cvtColor(train_data[20], cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(g)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = np.array(train_target)\n",
    "train_data = np.array(train_data)\n",
    "train_target = np.expand_dims(train_target, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('image_1.pkl', 'wb') as f1:\n",
    "    pickle.dump(train_data, f1)\n",
    "with open('image_target_1.pkl', 'wb') as f1:\n",
    "    pickle.dump(train_target, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('image_1.pkl','rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "with open('image_target_1.pkl','rb') as f:\n",
    "    train_target = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(featurewise_center=False,\n",
    "                                    featurewise_std_normalization=False,\n",
    "                                    rotation_range=10,\n",
    "                                    width_shift_range=0.1,\n",
    "                                    height_shift_range=0.1,\n",
    "                                    zoom_range=0.1,\n",
    "                                    rescale=1.0/255.0,\n",
    "                                    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = ImageDataGenerator(rescale=1.0/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_data, train_target, shuffle = True, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7500, 224, 224, 3), (7500, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500, 224, 224, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "def build_filters():\n",
    "    filters = []\n",
    "    ksize = 31\n",
    "    for theta in np.arange(0, np.pi, np.pi / 16):\n",
    "        kern = cv2.getGaborKernel((ksize, ksize), 4.0, theta, 10.0, 0.5, 0, ktype=cv2.CV_32F)\n",
    "        kern /= 1.5*kern.sum()\n",
    "        filters.append(kern)\n",
    "    return filters\n",
    "\n",
    "def image_func(img, filters):\n",
    "#     imgm=cv2.medianBlur(img, 3)\n",
    "#     img= np.expand_dims(imgm, axis = 2) - img\n",
    "#     return img.astype('float32')\n",
    "    accum = np.zeros_like(img)\n",
    "    for kern in filters:\n",
    "        fimg = cv2.filter2D(img, cv2.CV_8UC3, kern)\n",
    "        np.maximum(accum, fimg, accum)\n",
    "    return accum\n",
    "\n",
    "def image_tensor_func(img4d) :\n",
    "    results = []\n",
    "    filters = build_filters()\n",
    "    for img3d in img4d :\n",
    "        rimg3d = image_func(img3d , filters)\n",
    "        results.append( np.expand_dims( rimg3d, axis=0 ) )\n",
    "    return np.concatenate( results, axis = 0 )\n",
    "\n",
    "class Gabor(keras.layers.Layer ) :\n",
    "    def call( self, xin )  :\n",
    "        xout = tf.py_func( image_tensor_func, \n",
    "                           [xin],\n",
    "                           'float32',\n",
    "                           stateful=False,\n",
    "                           name='cvOpt')\n",
    "        xout = K.stop_gradient( xout )\n",
    "        xout.set_shape( [None, 224, 224, 3]) \n",
    "        return xout\n",
    "    def compute_output_shape( self, sin ) :\n",
    "        return (None, 224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "image_input = Input(shape = (224,224,3))\n",
    "\n",
    "my_layer = Gabor(name = 'gabor')(image_input)\n",
    "\n",
    "vggmodel = applications.VGG16(input_tensor=my_layer, weights='imagenet', include_top=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "gabor (Gabor)                (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 134,268,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "last_layer = vggmodel.get_layer('fc2').output\n",
    "out = Dense(2, activation='softmax', name='output')(last_layer)\n",
    "custom_vgg_model = Model(image_input, out)\n",
    "custom_vgg_model.summary()\n",
    "\n",
    "# for layer in custom_vgg_model.layers[:-1]:\n",
    "# \tlayer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in custom_vgg_model.layers[2:-1]:\n",
    "\tlayer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 2500 samples\n",
      "Epoch 1/12\n",
      "7500/7500 [==============================] - 958s 128ms/step - loss: 0.7370 - acc: 0.6513 - val_loss: 0.5289 - val_acc: 0.7488\n",
      "Epoch 2/12\n",
      "7500/7500 [==============================] - 977s 130ms/step - loss: 0.4824 - acc: 0.7728 - val_loss: 0.3819 - val_acc: 0.8244\n",
      "Epoch 3/12\n",
      "7500/7500 [==============================] - 974s 130ms/step - loss: 0.4040 - acc: 0.8144 - val_loss: 0.3316 - val_acc: 0.8360\n",
      "Epoch 4/12\n",
      "7500/7500 [==============================] - 976s 130ms/step - loss: 0.3583 - acc: 0.8496 - val_loss: 0.3371 - val_acc: 0.8580\n",
      "Epoch 5/12\n",
      "7500/7500 [==============================] - 967s 129ms/step - loss: 0.3096 - acc: 0.8739 - val_loss: 0.2709 - val_acc: 0.8920\n",
      "Epoch 6/12\n",
      "7500/7500 [==============================] - 961s 128ms/step - loss: 0.3488 - acc: 0.8555 - val_loss: 0.2548 - val_acc: 0.8948\n",
      "Epoch 7/12\n",
      "7500/7500 [==============================] - 975s 130ms/step - loss: 0.2710 - acc: 0.8932 - val_loss: 0.2618 - val_acc: 0.9180\n",
      "Epoch 8/12\n",
      "7500/7500 [==============================] - 979s 130ms/step - loss: 0.2626 - acc: 0.8964 - val_loss: 0.3165 - val_acc: 0.8800\n",
      "Epoch 9/12\n",
      "7500/7500 [==============================] - 981s 131ms/step - loss: 0.2764 - acc: 0.8975 - val_loss: 0.2760 - val_acc: 0.8876\n",
      "Epoch 10/12\n",
      "7500/7500 [==============================] - 1000s 133ms/step - loss: 0.2502 - acc: 0.9055 - val_loss: 0.2908 - val_acc: 0.8768\n",
      "Epoch 11/12\n",
      "7500/7500 [==============================] - 988s 132ms/step - loss: 0.2365 - acc: 0.9079 - val_loss: 0.3394 - val_acc: 0.8628\n",
      "Epoch 12/12\n",
      "7500/7500 [==============================] - 998s 133ms/step - loss: 0.2393 - acc: 0.9152 - val_loss: 0.2623 - val_acc: 0.9196\n"
     ]
    }
   ],
   "source": [
    "custom_vgg_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "hist = custom_vgg_model.fit(x_train, y_train, batch_size=20, epochs=12, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.array([[1, 2, 3], [2, 3, 4], [5, 6, 6]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
